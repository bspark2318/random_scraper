name: Daily Market Scraper

on:
  schedule:
    # Runs at 8:00 AM UTC every day (adjust timezone as needed)
    - cron: '0 8 * * *'
  workflow_dispatch:  # Allows manual trigger from GitHub UI

jobs:
  scrape-and-analyze:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y wget gnupg
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run scraper
        env:
          OPENAI_KEY: ${{ secrets.OPENAI_KEY }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: python main.py

      - name: Upload logs (if needed)
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: scraper-logs
          path: |
            *.log
            cache/
          retention-days: 7
